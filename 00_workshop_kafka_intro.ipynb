{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial steps in Azure"
      ],
      "metadata": {
        "id": "1XfJ22pQdu-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Login to your azure students account https://azure.microsoft.com/cs-cz/free/students/ and create a resource, where you will host your services.\n",
        "\n",
        "<img src=\"https://i.imgur.com/psNFWvl.png\" width=\"40%\">\n",
        "\n"
      ],
      "metadata": {
        "id": "4gLB4WgAbaOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Databricks Workspace \n",
        "\n",
        "<img src=\"https://i.imgur.com/L4prXMA.png\" width=\"40%\">\n"
      ],
      "metadata": {
        "id": "-DguvAPtbnEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select your newly created Dbx workspace, Launch, Sign in and voila.\n",
        "\n",
        "<img src=\"https://i.imgur.com/TMS6y98.png\" alt=\"Databricks Launch Logo\" width=\"60%\"/>"
      ],
      "metadata": {
        "id": "T38OrJqwdr5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial steps in Databricks"
      ],
      "metadata": {
        "id": "YKo238L0d3x9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect your GIT repo"
      ],
      "metadata": {
        "id": "FsehSiqkeqdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate personal access token from your git provider, see [github](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token), [gitlab](https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html)\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/awugvC8.png\" alt=\"Git Integration\" width=\"50%\"/>\n",
        "\n",
        "Navigate to Repos and add your repository; pull if anything present \n",
        "\n",
        "<img src=\"https://i.imgur.com/AM4s5pr.png\" alt=\"Databricks Repos\" width=\"90%\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "Wybkmki_jdvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a cluster"
      ],
      "metadata": {
        "id": "BbJuTDxkgFUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navigate to Computer and create desired cluster. Be reasonable with resources and termination time.\n",
        "\n",
        "Be advised, while streaming you will need to terminate the cluster manually, because the termination time is only for clusters that are idle.\n",
        "\n",
        "For first runs and debug, single node is enough.\n",
        "\n",
        "<img src=\"https://i.imgur.com/tiIOqaC.png\" alt=\"single node\" width=\"40%\"/>\n",
        "\n",
        "Once you are sure with solution, you may test your solution on a stronger cluster with bigger amount of data, see multi node cluster below. \n",
        "\n",
        "<img src=\"https://i.imgur.com/Orzkjeu.png\" alt=\"multi cluster\" width=\"40%\"/>\n"
      ],
      "metadata": {
        "id": "FgiZ1k4cxsUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Notebook"
      ],
      "metadata": {
        "id": "tVSsvPUB10gO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can create either notebook, which is not connected to your repository, or create a Repo files, which you can git control. **We will use git controlled files.** GIT in Databricks environment has some limitations, eg. merging is not possible. \n",
        "\n",
        "***Repos/choose_your_repo/choose_your_branch/Create/Notebook***\n",
        "\n",
        "You can Create branch via *Git...* option or in git gui/console.\n",
        "\n",
        "When you want to use Databricks cluster and Databricks features, it is not neccessary to use Databricks GUI. It is also possible to use Visual Code, with simple Azure verification and Databricks plugin. Feel free to explore, but it is beyond this course.\n",
        "\n",
        "<img src=\"https://i.imgur.com/6YsDCqF.png\" alt=\"Create a Notebook in Repo\" width=\"60%\"/>"
      ],
      "metadata": {
        "id": "L-RtfRkx19ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once your Notebook is created, you are free to code and run it against cluster.\n",
        "\n",
        "Starting a cluster will take some time, few minutes.\n",
        "\n",
        "<img src=\"https://i.imgur.com/EHmbUVJ.png\" alt=\"Run Notebook\" width=\"40%\"/>"
      ],
      "metadata": {
        "id": "PEGumTdu5jW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's get started with kafka"
      ],
      "metadata": {
        "id": "ldPK5fIs5nZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kafka brief review"
      ],
      "metadata": {
        "id": "v9V3vyjsPUw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kafka is\n",
        "\n",
        "*   Scalable - distributed architecture capable of handling huge amount of incoming messages in high speed. \n",
        "*   High Throughput - Thousands messages per second, depends on the cluster.\n",
        "*   Low Latency - the latency = time take for a system to process a single event is under 10ms.\n",
        "*   Fault Tolerance - it is possible to use replication, which helps Kafka handle failures at nodesin the cluster. \n",
        "Durability - Kafka can persist data for desired amount of time.\n",
        "*   Reliability -  all of above makes Kafka very popular, the most used and reliable messaging system.\n",
        "\n",
        "Ability to handle real-time data: Kafka supports real-time data handling and is an excellent choice when data has to be processed in real-time.\n",
        "\n",
        "![kafka architecture](https://daxg39y63pxwu.cloudfront.net/images/blog/apache-kafka-architecture-/image_7224627121625733881346.png)\n",
        "\n",
        "\n",
        "**Broker**\n",
        "Broker works as a container that can hold multiple topics with different partitions.\n",
        "\n",
        "**Topic**\n",
        "Kafka stores its data in streams, called topics. Topics are append-only, immutable logs of events. Typically, events of the same type, or events that are in some way related, would go into the same topic.\n",
        "\n",
        "**Consumer**\n",
        "Can read/pull/subscribe present data from kafka topics.\n",
        "\n",
        "**Producer**\n",
        "Can write/push/publish new data to kafka topics."
      ],
      "metadata": {
        "id": "kIXN2ZKEPsbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Kafka"
      ],
      "metadata": {
        "id": "9knPVjoYKvGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download desired version in https://kafka.apache.org/downloads \n",
        "When on local, you will need to start zookeeper and kafka server. For this, you will need to navigate into your kafka folder in console. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wcPj6KhtK8xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tar -xzf kafka_2.13-3.3.1.tgz\n",
        "\n",
        "cd kafka_2.13-3.3.1 seznamu\n",
        "\n",
        "\n",
        "# Start the ZooKeeper service\n",
        "bin/zookeeper-server-start.sh config/zookeeper.properties\n",
        "\n",
        "# Start the Kafka broker service\n",
        "bin/kafka-server-start.sh config/server.properties"
      ],
      "metadata": {
        "id": "cSTwP1r2LePh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "makgfMRz6cco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a topic"
      ],
      "metadata": {
        "id": "Km-VvCRtL73g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using local server as a bootstrap server, so the address is localhost and standard port 9092."
      ],
      "metadata": {
        "id": "vWe-2M44MGVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin/kafka-topics.sh --create --topic first-topic --bootstrap-server localhost:9092"
      ],
      "metadata": {
        "id": "C2v2hiY1MAk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create some events"
      ],
      "metadata": {
        "id": "oFSSze9mM2CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you start console producer (it is prepared script for reading from console), it will wait for your input. You can kill it with `Ctrl+C`. "
      ],
      "metadata": {
        "id": "DUAIMoaENfYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin/kafka-console-producer.sh --topic first-topic --bootstrap-server localhost:9092\n",
        "First message\n",
        "Second message"
      ],
      "metadata": {
        "id": "KcERFjFMM0zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read events from topic"
      ],
      "metadata": {
        "id": "1euDenwlNzUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open a new console window, not to kill producer. Run console consumer to read messages you have sent earlier. You can read from beginning (by adding --from-beginning). Once script started, you should see appearing messages sent earlier, or real time in the producer window."
      ],
      "metadata": {
        "id": "b6p4TqH7N2Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin/kafka-console-consumer.sh --topic first-topic --from-beginning --bootstrap-server localhost:9092"
      ],
      "metadata": {
        "id": "p8d2GYFzN5h7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}